{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28aeed5",
   "metadata": {},
   "source": [
    "## Step 1: í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e58eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -q transformers einops huggingface_hub matplotlib scikit-learn biopython torch pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db422e70",
   "metadata": {},
   "source": [
    "## Step 2: ëª¨ë“ˆ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55ee296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€ (ëª¨ë“ˆ ë¡œë“œìš©)\n",
    "current_dir = Path('.').resolve()\n",
    "project_root = current_dir.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from preparation import get_device, load_models\n",
    "from sequence_generation import (\n",
    "    fetch_gene_sequences, sort_genes_by_length, \n",
    "    DEFAULT_DECODING_STRATEGIES\n",
    ")\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b9fca",
   "metadata": {},
   "source": [
    "## Step 3: ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bbe497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.9.1\n",
      "Using device: mps\n",
      "\n",
      "ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: mps\n"
     ]
    }
   ],
   "source": [
    "# ë””ë°”ì´ìŠ¤ ê°ì§€ (CUDA / MPS / CPU)\n",
    "device = get_device()\n",
    "print(f\"\\nì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c63ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Downloading DNABERT-2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b41f45ed264f5f968abca568daea48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DNABERT-2 Triton patch applied successfully.\n",
      "[DNABERT-2] Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DNABERT-2] Model loaded successfully.\n",
      "âœ… DNABERT-2 loaded successfully.\n",
      "[NT-v2-500m] Loading model...\n",
      "[NT-v2-500m] Model loaded successfully.\n",
      "âœ… NT-v2-500m loaded successfully.\n",
      "\n",
      "ğŸš€ 2 model(s) ready!\n",
      "ë¡œë“œëœ ëª¨ë¸: ['DNABERT-2', 'NT-v2-500m']\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model_configs = {\n",
    "    \"DNABERT-2\": \"zhihan1996/DNABERT-2-117M\",\n",
    "    # \"NT-v2-50m\": \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\",\n",
    "    \"NT-v2-500m\": \"InstaDeepAI/nucleotide-transformer-v2-500m-multi-species\",\n",
    "}\n",
    "\n",
    "models = load_models(device, model_configs=model_configs)\n",
    "print(f\"ë¡œë“œëœ ëª¨ë¸: {list(models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f6df9",
   "metadata": {},
   "source": [
    "## Step 4: ìœ ì „ì ì‹œí€€ìŠ¤ ìˆ˜ì§‘ ë° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae20cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„¤ì •:\n",
      "  - ë°˜ë³µ íšŸìˆ˜: 30\n",
      "  - ë§ˆìŠ¤í‚¹ ë¹„ìœ¨: 0.2\n",
      "  - ê²°ê³¼ ë””ë ‰í† ë¦¬: results/sequences\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì •\n",
    "NCBI_EMAIL = \"your_email@example.com\"\n",
    "ITERATIONS = 30  # ì§„í™” ìŠ¤í… ìˆ˜\n",
    "MASK_RATIO = 0.2  # ë§ˆìŠ¤í‚¹ ë¹„ìœ¨\n",
    "RESULTS_DIR = Path('results/sequences')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"ì„¤ì •:\")\n",
    "print(f\"  - ë°˜ë³µ íšŸìˆ˜: {ITERATIONS}\")\n",
    "print(f\"  - ë§ˆìŠ¤í‚¹ ë¹„ìœ¨: {MASK_RATIO}\")\n",
    "print(f\"  - ê²°ê³¼ ë””ë ‰í† ë¦¬: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d012fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching gene sequences from NCBI...\n",
      "Fetching H4C1 by UID NM_003538...\n",
      "  âœ… Found and added sequence for H4C1 (Length: 402bp)\n",
      "Fetching TP53 by UID NM_000546...\n",
      "  âœ… Found and added sequence for TP53 (Length: 2512bp)\n",
      "Fetching GAPDH by UID NM_002046...\n",
      "  âœ… Found and added sequence for GAPDH (Length: 1285bp)\n",
      "Fetching GAPDHP1 by UID NG_001123...\n",
      "  âœ… Found and added sequence for GAPDHP1 (Length: 1098bp)\n",
      "Fetching NORAD by UID NR_027451...\n",
      "  âœ… Found and added sequence for NORAD (Length: 5378bp)\n",
      "Fetching STAT3 by UID NM_139276...\n",
      "  âœ… Found and added sequence for STAT3 (Length: 4921bp)\n",
      "Fetching TTN by UID NM_001267550...\n",
      "  âœ… Found and added sequence for TTN (Length: 109224bp)\n",
      "Fetching HBB by UID NM_000518...\n",
      "  âœ… Found and added sequence for HBB (Length: 628bp)\n",
      "Fetching HOXC11 by UID NM_014212...\n",
      "  âœ… Found and added sequence for HOXC11 (Length: 3261bp)\n",
      "Fetching HOTAIR by UID NR_003716...\n",
      "  âœ… Found and added sequence for HOTAIR (Length: 2273bp)\n",
      "Fetching VEGFA by UID NM_003376...\n",
      "  âœ… Found and added sequence for VEGFA (Length: 3609bp)\n",
      "Fetching NEAT1 by UID NR_003513...\n",
      "  âœ… Found and added sequence for NEAT1 (Length: 3190bp)\n",
      "Fetching PTEN by UID NM_000314...\n",
      "  âœ… Found and added sequence for PTEN (Length: 8515bp)\n",
      "Fetching PTENP1 by UID NR_023917...\n",
      "  âœ… Found and added sequence for PTENP1 (Length: 3932bp)\n",
      "Fetching TPI1 by UID NM_000365...\n",
      "  âœ… Found and added sequence for TPI1 (Length: 1351bp)\n",
      "Fetching TPI1P1 by UID NG_008262.2...\n",
      "  âœ… Found and added sequence for TPI1P1 (Length: 1471bp)\n",
      "\n",
      "âœ… Gene fetching complete!\n",
      "Genes successfully loaded: ['H4C1', 'TP53', 'GAPDH', 'GAPDHP1', 'NORAD', 'STAT3', 'TTN', 'HBB', 'HOXC11', 'HOTAIR', 'VEGFA', 'NEAT1', 'PTEN', 'PTENP1', 'TPI1', 'TPI1P1']\n",
      "\n",
      "ìˆ˜ì§‘ëœ ìœ ì „ì:\n",
      "  - H4C1: 402 bp\n",
      "  - HBB: 628 bp\n",
      "  - GAPDHP1: 1098 bp\n",
      "  - GAPDH: 1285 bp\n",
      "  - TPI1: 1351 bp\n",
      "  - TPI1P1: 1471 bp\n",
      "  - HOTAIR: 2273 bp\n",
      "  - TP53: 2512 bp\n",
      "  - NEAT1: 3190 bp\n",
      "  - HOXC11: 3261 bp\n",
      "  - VEGFA: 3609 bp\n",
      "  - PTENP1: 3932 bp\n",
      "  - STAT3: 4921 bp\n",
      "  - NORAD: 5378 bp\n",
      "  - PTEN: 8515 bp\n",
      "  - TTN: 109224 bp\n"
     ]
    }
   ],
   "source": [
    "# ìœ ì „ì ì‹œí€€ìŠ¤ ìˆ˜ì§‘\n",
    "gene_selection = fetch_gene_sequences(NCBI_EMAIL)\n",
    "gene_selection = sort_genes_by_length(gene_selection)\n",
    "\n",
    "print(\"\\nìˆ˜ì§‘ëœ ìœ ì „ì:\")\n",
    "for gene, seq in gene_selection.items():\n",
    "    print(f\"  - {gene}: {len(seq)} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3992a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...\n",
      "======================================================================\n",
      "\n",
      "ëª¨ë¸: DNABERT-2\n",
      "  H4C1... âœ“ (4 strategies)\n",
      "  HBB... âœ“ (4 strategies)\n",
      "  GAPDHP1... âœ“ (4 strategies)\n",
      "  GAPDH... âœ“ (4 strategies)\n",
      "  TPI1... âœ“ (4 strategies)\n",
      "  TPI1P1... âœ“ (4 strategies)\n",
      "  HOTAIR..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 512 to 516\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 516 to 523\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 523 to 528\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  TP53..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 528 to 535\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 535 to 539\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 539 to 543\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 543 to 546\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 546 to 549\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 549 to 552\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 552 to 557\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 557 to 562\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 562 to 563\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 563 to 565\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 565 to 571\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 571 to 575\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 575 to 580\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 580 to 584\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 584 to 586\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  NEAT1..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 586 to 641\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 641 to 644\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 644 to 648\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 648 to 649\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 649 to 654\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 654 to 658\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 658 to 664\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 664 to 672\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 672 to 673\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 673 to 677\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 677 to 682\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 682 to 685\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 685 to 687\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 687 to 689\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 689 to 696\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 696 to 699\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 699 to 700\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 700 to 704\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 704 to 705\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 705 to 708\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 708 to 713\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 713 to 717\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 717 to 725\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  HOXC11..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 725 to 728\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 728 to 733\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  VEGFA..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 733 to 735\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 735 to 743\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 743 to 747\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 747 to 749\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 749 to 754\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 754 to 757\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 757 to 758\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 758 to 761\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 761 to 769\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 769 to 772\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 772 to 774\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 774 to 778\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 778 to 780\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 780 to 789\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 789 to 791\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 791 to 797\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 797 to 801\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 801 to 806\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 806 to 811\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 811 to 816\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 816 to 821\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 821 to 822\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  PTENP1..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 822 to 828\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 828 to 835\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 835 to 840\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 840 to 842\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 842 to 844\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 844 to 845\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 845 to 851\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 851 to 852\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 852 to 855\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 855 to 860\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 860 to 862\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 862 to 868\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 868 to 871\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 871 to 878\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 878 to 886\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 886 to 889\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  STAT3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 889 to 983\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 983 to 993\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 993 to 994\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 994 to 999\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 999 to 1002\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1002 to 1007\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1007 to 1012\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1012 to 1020\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1020 to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  NORAD... âœ“ (4 strategies)\n",
      "  PTEN... âœ“ (4 strategies)\n",
      "  TTN... âœ“ (4 strategies)\n",
      "\n",
      "ëª¨ë¸: NT-v2-500m\n",
      "  H4C1... âœ“ (4 strategies)\n",
      "  HBB... âœ“ (4 strategies)\n",
      "  GAPDHP1... âœ“ (4 strategies)\n",
      "  GAPDH... âœ“ (4 strategies)\n",
      "  TPI1... âœ“ (4 strategies)\n",
      "  TPI1P1... âœ“ (4 strategies)\n",
      "  HOTAIR... âœ“ (4 strategies)\n",
      "  TP53... âœ“ (4 strategies)\n",
      "  NEAT1... âœ“ (4 strategies)\n",
      "  HOXC11... âœ“ (4 strategies)\n",
      "  VEGFA... âœ“ (4 strategies)\n",
      "  PTENP1... âœ“ (4 strategies)\n",
      "  STAT3... âœ“ (4 strategies)\n",
      "  NORAD... âœ“ (4 strategies)\n",
      "  PTEN... âœ“ (4 strategies)\n",
      "  TTN... âœ“ (4 strategies)\n",
      "\n",
      "======================================================================\n",
      "âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ!\n",
      "ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: results/sequences\n",
      "ğŸ§¹ ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì‚­ì œ ì™„ë£Œ: 4 files\n"
     ]
    }
   ],
   "source": [
    "# ì‹œí€€ìŠ¤ ìƒì„± ë° CSV ì €ì¥\n",
    "print(\"\\nì‹œí€€ìŠ¤ ìƒì„± ì¤‘...\\n\" + \"=\"*70)\n",
    "\n",
    "for model_label, model_instance in models.items():\n",
    "    print(f\"\\nëª¨ë¸: {model_label}\")\n",
    "    \n",
    "    for gene_id, original_sequence in gene_selection.items():\n",
    "        print(f\"  {gene_id}...\", end=\"\", flush=True)\n",
    "        \n",
    "        # ì¶œë ¥ ê²½ë¡œ\n",
    "        model_name = model_label.replace(\"/\", \"-\")\n",
    "        model_dir = RESULTS_DIR / model_name\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_csv = model_dir / f\"{gene_id}.csv\"\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥ìš© ë°ì´í„°í”„ë ˆì„\n",
    "        results_data = {}\n",
    "        \n",
    "        for strategy_base_key, strategy_cfg in DEFAULT_DECODING_STRATEGIES.items():\n",
    "            strategy_type = strategy_cfg[\"type\"]\n",
    "            temperatures = strategy_cfg.get(\"temperatures\", [1.0])\n",
    "            top_k = strategy_cfg.get(\"top_k\", 50)\n",
    "            \n",
    "            for temp in temperatures:\n",
    "                # ì „ëµ ì´ë¦„\n",
    "                if strategy_type == \"greedy\":\n",
    "                    strategy_key = strategy_base_key\n",
    "                else:\n",
    "                    strategy_key = f\"{strategy_base_key}_t{temp}\"\n",
    "                \n",
    "                # ì‹œí€€ìŠ¤ ìƒì„±\n",
    "                generated_sequences = model_instance.run(\n",
    "                    sequence=original_sequence,\n",
    "                    steps=ITERATIONS,\n",
    "                    mask_ratio=MASK_RATIO,\n",
    "                    strategy=strategy_type,\n",
    "                    temperature=temp,\n",
    "                    top_k=top_k,\n",
    "                    save_all=True,\n",
    "                    save_interval=1\n",
    "                )\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥ (ê° iterationì„ columnìœ¼ë¡œ)\n",
    "                results_data[strategy_key] = generated_sequences\n",
    "                \n",
    "                # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "                del generated_sequences\n",
    "                gc.collect()\n",
    "                if device == \"cuda\":\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif device == \"mps\":\n",
    "                    torch.mps.empty_cache()\n",
    "        \n",
    "        # DataFrame ìƒì„± (decoding strategyë¥¼ rowë¡œ)\n",
    "        df = pd.DataFrame(results_data).T\n",
    "        \n",
    "        # ì—´ ì´ë¦„ì„ iteration ë²ˆí˜¸ë¡œ ì„¤ì •\n",
    "        df.columns = [f\"iteration_{i}\" for i in range(df.shape[1])]\n",
    "        \n",
    "        # CSV ì €ì¥\n",
    "        df.to_csv(output_csv)\n",
    "        \n",
    "        print(f\" âœ“ ({len(df)} strategies)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {RESULTS_DIR}\")\n",
    "\n",
    "# ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì •ë¦¬ (ìƒˆ ì‹œí€€ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ê³„ì‚° í•„ìš”)\n",
    "embeddings_dir = Path('results/embeddings')\n",
    "if embeddings_dir.exists():\n",
    "    removed = 0\n",
    "    for cache_file in embeddings_dir.glob('**/*.pkl'):\n",
    "        try:\n",
    "            cache_file.unlink()\n",
    "            removed += 1\n",
    "        except Exception as e:\n",
    "            print(f'  ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {cache_file} ({e})')\n",
    "    print(f'ğŸ§¹ ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì‚­ì œ ì™„ë£Œ: {removed} files')\n",
    "else:\n",
    "    print('ğŸ§¹ ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì—†ìŒ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a13f2",
   "metadata": {},
   "source": [
    "## ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff760ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ ê²°ê³¼ í™•ì¸:\n",
      "\n",
      "======================================================================\n",
      "\n",
      "DNABERT-2:\n",
      "  H4C1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "NT-v2-500m:\n",
      "  H4C1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"ìƒì„±ëœ ê²°ê³¼ í™•ì¸:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_key in models.keys():\n",
    "    model_name = model_key.replace(\"/\", \"-\")\n",
    "    model_dir = RESULTS_DIR / model_name\n",
    "    \n",
    "    print(f\"\\n{model_key}:\")\n",
    "    \n",
    "    for gene_id in gene_selection.keys():\n",
    "        csv_file = model_dir / f\"{gene_id}.csv\"\n",
    "        if csv_file.exists():\n",
    "            df = pd.read_csv(csv_file, index_col=0)\n",
    "            num_strategies = len(df)\n",
    "            num_iterations = len(df.columns)\n",
    "            print(f\"  {gene_id:10s}: {num_strategies:2d} strategies, {num_iterations:2d} iterations\")\n",
    "            if num_strategies > 0:\n",
    "                print(f\"            First strategy: {df.index[0]}\")\n",
    "        else:\n",
    "            print(f\"  {gene_id:10s}: âœ— FILE NOT FOUND\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
