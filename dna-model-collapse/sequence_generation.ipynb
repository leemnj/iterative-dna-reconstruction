{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28aeed5",
   "metadata": {},
   "source": [
    "## Step 1: í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e58eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -q transformers einops huggingface_hub matplotlib scikit-learn biopython torch pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db422e70",
   "metadata": {},
   "source": [
    "## Step 2: ëª¨ë“ˆ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55ee296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€ (ëª¨ë“ˆ ë¡œë“œìš©)\n",
    "current_dir = Path('.').resolve()\n",
    "if str(current_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(current_dir))\n",
    "\n",
    "# ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from preparation import get_device, load_models\n",
    "from sequence_generation import (\n",
    "    fetch_gene_sequences, sort_genes_by_length, \n",
    "    DEFAULT_DECODING_STRATEGIES\n",
    ")\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b9fca",
   "metadata": {},
   "source": [
    "## Step 3: ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbe497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.9.1\n",
      "Using device: mps\n",
      "\n",
      "ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: mps\n"
     ]
    }
   ],
   "source": [
    "# ë””ë°”ì´ìŠ¤ ê°ì§€ (CUDA / MPS / CPU)\n",
    "device = get_device()\n",
    "print(f\"\\nì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c63ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Downloading DNABERT-2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4892a335e5f24a0b992b9ee1967c7b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DNABERT-2 Triton patch applied successfully.\n",
      "[DNABERT-2] Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DNABERT-2] Model loaded successfully.\n",
      "âœ… DNABERT-2 loaded successfully.\n",
      "[NT-v2-500m] Loading model...\n",
      "[NT-v2-500m] Model loaded successfully.\n",
      "âœ… NT-v2-500m loaded successfully.\n",
      "\n",
      "ğŸš€ 2 model(s) ready!\n",
      "ë¡œë“œëœ ëª¨ë¸: ['DNABERT-2', 'NT-v2-500m']\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model_configs = {\n",
    "    \"DNABERT-2\": \"zhihan1996/DNABERT-2-117M\",\n",
    "    # \"NT-v2-50m\": \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\",\n",
    "    \"NT-v2-500m\": \"InstaDeepAI/nucleotide-transformer-v2-500m-multi-species\",\n",
    "}\n",
    "\n",
    "models = load_models(device, model_configs=model_configs)\n",
    "print(f\"ë¡œë“œëœ ëª¨ë¸: {list(models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f6df9",
   "metadata": {},
   "source": [
    "## Step 4: ìœ ì „ì ì‹œí€€ìŠ¤ ìˆ˜ì§‘ ë° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae20cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„¤ì •:\n",
      "  - ë°˜ë³µ íšŸìˆ˜: 50\n",
      "  - ë§ˆìŠ¤í‚¹ ë¹„ìœ¨: 0.2\n",
      "  - ê²°ê³¼ ë””ë ‰í† ë¦¬: results/sequences\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì •\n",
    "NCBI_EMAIL = \"your_email@example.com\"\n",
    "ITERATIONS = 50  # ì§„í™” ìŠ¤í… ìˆ˜\n",
    "MASK_RATIO = 0.2  # ë§ˆìŠ¤í‚¹ ë¹„ìœ¨\n",
    "RESULTS_DIR = Path('results/sequences')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"ì„¤ì •:\")\n",
    "print(f\"  - ë°˜ë³µ íšŸìˆ˜: {ITERATIONS}\")\n",
    "print(f\"  - ë§ˆìŠ¤í‚¹ ë¹„ìœ¨: {MASK_RATIO}\")\n",
    "print(f\"  - ê²°ê³¼ ë””ë ‰í† ë¦¬: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d012fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching gene sequences from NCBI...\n",
      "Fetching H4C1 by UID NM_003538...\n",
      "  âœ… Found and added sequence for H4C1 (Length: 402bp)\n",
      "Fetching TP53 by UID NM_000546...\n",
      "  âœ… Found and added sequence for TP53 (Length: 2512bp)\n",
      "Fetching GAPDH by UID NM_002046...\n",
      "  âœ… Found and added sequence for GAPDH (Length: 1285bp)\n",
      "Fetching GAPDHP1 by UID NG_001123...\n",
      "  âœ… Found and added sequence for GAPDHP1 (Length: 1098bp)\n",
      "Fetching NORAD by UID NR_027451...\n",
      "  âœ… Found and added sequence for NORAD (Length: 5378bp)\n",
      "Fetching STAT3 by UID NM_139276...\n",
      "  âœ… Found and added sequence for STAT3 (Length: 4921bp)\n",
      "Fetching TTN by UID NM_001267550...\n",
      "  âœ… Found and added sequence for TTN (Length: 109224bp)\n",
      "Fetching HBB by UID NM_000518...\n",
      "  âœ… Found and added sequence for HBB (Length: 628bp)\n",
      "Fetching HOXC11 by UID NM_014212...\n",
      "  âœ… Found and added sequence for HOXC11 (Length: 3261bp)\n",
      "Fetching HOTAIR by UID NR_003716...\n",
      "  âœ… Found and added sequence for HOTAIR (Length: 2273bp)\n",
      "Fetching VEGFA by UID NM_003376...\n",
      "  âœ… Found and added sequence for VEGFA (Length: 3609bp)\n",
      "Fetching NEAT1 by UID NR_003513...\n",
      "  âœ… Found and added sequence for NEAT1 (Length: 3190bp)\n",
      "Fetching PTEN by UID NM_000314...\n",
      "  âœ… Found and added sequence for PTEN (Length: 8515bp)\n",
      "Fetching PTENP1 by UID NR_023917...\n",
      "  âœ… Found and added sequence for PTENP1 (Length: 3932bp)\n",
      "Fetching TPI1 by UID NM_000365...\n",
      "  âœ… Found and added sequence for TPI1 (Length: 1351bp)\n",
      "Fetching TPI1P1 by UID NG_008262.2...\n",
      "  âœ… Found and added sequence for TPI1P1 (Length: 1471bp)\n",
      "\n",
      "âœ… Gene fetching complete!\n",
      "Genes successfully loaded: ['H4C1', 'TP53', 'GAPDH', 'GAPDHP1', 'NORAD', 'STAT3', 'TTN', 'HBB', 'HOXC11', 'HOTAIR', 'VEGFA', 'NEAT1', 'PTEN', 'PTENP1', 'TPI1', 'TPI1P1']\n",
      "\n",
      "ìˆ˜ì§‘ëœ ìœ ì „ì:\n",
      "  - H4C1: 402 bp\n",
      "  - HBB: 628 bp\n",
      "  - GAPDHP1: 1098 bp\n",
      "  - GAPDH: 1285 bp\n",
      "  - TPI1: 1351 bp\n",
      "  - TPI1P1: 1471 bp\n",
      "  - HOTAIR: 2273 bp\n",
      "  - TP53: 2512 bp\n",
      "  - NEAT1: 3190 bp\n",
      "  - HOXC11: 3261 bp\n",
      "  - VEGFA: 3609 bp\n",
      "  - PTENP1: 3932 bp\n",
      "  - STAT3: 4921 bp\n",
      "  - NORAD: 5378 bp\n",
      "  - PTEN: 8515 bp\n",
      "  - TTN: 109224 bp\n"
     ]
    }
   ],
   "source": [
    "# ìœ ì „ì ì‹œí€€ìŠ¤ ìˆ˜ì§‘\n",
    "gene_selection = fetch_gene_sequences(NCBI_EMAIL)\n",
    "gene_selection = sort_genes_by_length(gene_selection)\n",
    "\n",
    "print(\"\\nìˆ˜ì§‘ëœ ìœ ì „ì:\")\n",
    "for gene, seq in gene_selection.items():\n",
    "    print(f\"  - {gene}: {len(seq)} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3992a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...\n",
      "======================================================================\n",
      "\n",
      "ëª¨ë¸: DNABERT-2\n",
      "  H4C1... âœ“ (4 strategies)\n",
      "  HBB... âœ“ (4 strategies)\n",
      "  GAPDHP1... âœ“ (4 strategies)\n",
      "  GAPDH... âœ“ (4 strategies)\n",
      "  TPI1... âœ“ (4 strategies)\n",
      "  TPI1P1... âœ“ (4 strategies)\n",
      "  HOTAIR..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 512 to 513\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 513 to 515\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 515 to 518\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 518 to 525\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 525 to 526\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 526 to 532\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 532 to 533\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 533 to 534\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 534 to 536\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 536 to 540\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 540 to 543\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 543 to 546\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 546 to 549\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  TP53..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 549 to 550\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 550 to 556\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 556 to 557\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 557 to 565\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 565 to 566\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 566 to 568\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 568 to 569\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 569 to 571\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 571 to 572\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 572 to 575\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 575 to 577\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 577 to 578\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 578 to 581\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 581 to 584\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 584 to 587\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 587 to 592\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 592 to 593\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 593 to 596\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 596 to 598\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 598 to 606\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 606 to 612\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  NEAT1..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 612 to 641\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 641 to 642\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 642 to 644\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 644 to 646\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 646 to 652\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 652 to 653\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 653 to 658\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 658 to 664\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 664 to 669\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 669 to 674\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 674 to 678\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 678 to 681\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 681 to 687\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 687 to 693\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 693 to 698\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 698 to 700\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 700 to 703\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 703 to 709\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 709 to 716\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 716 to 723\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 723 to 729\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 729 to 734\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 734 to 735\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 735 to 738\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 738 to 741\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 741 to 744\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 744 to 755\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 755 to 766\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 766 to 769\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 769 to 773\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 773 to 780\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 780 to 786\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 786 to 788\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 788 to 794\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 794 to 801\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 801 to 807\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 807 to 814\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 814 to 818\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 818 to 819\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 819 to 821\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 821 to 826\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 826 to 829\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  HOXC11... âœ“ (4 strategies)\n",
      "  VEGFA..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 829 to 831\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 831 to 840\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 840 to 845\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 845 to 848\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 848 to 857\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 857 to 860\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 860 to 863\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 863 to 872\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 872 to 878\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 878 to 882\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 882 to 890\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 890 to 892\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 892 to 897\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 897 to 909\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 909 to 911\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 911 to 918\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 918 to 925\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 925 to 931\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 931 to 936\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 936 to 945\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  PTENP1..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 945 to 948\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 948 to 953\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  STAT3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 953 to 983\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 983 to 985\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 985 to 990\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 990 to 992\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 992 to 998\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 998 to 1005\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1005 to 1012\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1012 to 1019\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1019 to 1021\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1021 to 1023\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1023 to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ“ (4 strategies)\n",
      "  NORAD... âœ“ (4 strategies)\n",
      "  PTEN... âœ“ (4 strategies)\n",
      "  TTN... âœ“ (4 strategies)\n",
      "\n",
      "ëª¨ë¸: NT-v2-500m\n",
      "  H4C1... âœ“ (4 strategies)\n",
      "  HBB... âœ“ (4 strategies)\n",
      "  GAPDHP1... âœ“ (4 strategies)\n",
      "  GAPDH... âœ“ (4 strategies)\n",
      "  TPI1... âœ“ (4 strategies)\n",
      "  TPI1P1... âœ“ (4 strategies)\n",
      "  HOTAIR... âœ“ (4 strategies)\n",
      "  TP53... âœ“ (4 strategies)\n",
      "  NEAT1... âœ“ (4 strategies)\n",
      "  HOXC11... âœ“ (4 strategies)\n",
      "  VEGFA... âœ“ (4 strategies)\n",
      "  PTENP1... âœ“ (4 strategies)\n",
      "  STAT3... âœ“ (4 strategies)\n",
      "  NORAD... âœ“ (4 strategies)\n",
      "  PTEN... âœ“ (4 strategies)\n",
      "  TTN... âœ“ (4 strategies)\n",
      "\n",
      "======================================================================\n",
      "âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ!\n",
      "ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: results/sequences\n",
      "ğŸ§¹ ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "# ì‹œí€€ìŠ¤ ìƒì„± ë° CSV ì €ì¥\n",
    "print(\"\\nì‹œí€€ìŠ¤ ìƒì„± ì¤‘...\\n\" + \"=\"*70)\n",
    "\n",
    "for model_label, model_instance in models.items():\n",
    "    print(f\"\\nëª¨ë¸: {model_label}\")\n",
    "    \n",
    "    for gene_id, original_sequence in gene_selection.items():\n",
    "        print(f\"  {gene_id}...\", end=\"\", flush=True)\n",
    "        \n",
    "        # ì¶œë ¥ ê²½ë¡œ\n",
    "        model_name = model_label.replace(\"/\", \"-\")\n",
    "        model_dir = RESULTS_DIR / model_name\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_csv = model_dir / f\"{gene_id}.csv\"\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥ìš© ë°ì´í„°í”„ë ˆì„\n",
    "        results_data = {}\n",
    "        \n",
    "        for strategy_base_key, strategy_cfg in DEFAULT_DECODING_STRATEGIES.items():\n",
    "            strategy_type = strategy_cfg[\"type\"]\n",
    "            temperatures = strategy_cfg.get(\"temperatures\", [1.0])\n",
    "            top_k = strategy_cfg.get(\"top_k\", 50)\n",
    "            \n",
    "            for temp in temperatures:\n",
    "                # ì „ëµ ì´ë¦„\n",
    "                if strategy_type == \"greedy\":\n",
    "                    strategy_key = strategy_base_key\n",
    "                else:\n",
    "                    strategy_key = f\"{strategy_base_key}_t{temp}\"\n",
    "                \n",
    "                # ì‹œí€€ìŠ¤ ìƒì„±\n",
    "                generated_sequences = model_instance.run(\n",
    "                    sequence=original_sequence,\n",
    "                    steps=ITERATIONS,\n",
    "                    mask_ratio=MASK_RATIO,\n",
    "                    strategy=strategy_type,\n",
    "                    temperature=temp,\n",
    "                    top_k=top_k,\n",
    "                    save_all=True,\n",
    "                    save_interval=1\n",
    "                )\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥ (ê° iterationì„ columnìœ¼ë¡œ)\n",
    "                results_data[strategy_key] = generated_sequences\n",
    "                \n",
    "                # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "                del generated_sequences\n",
    "                gc.collect()\n",
    "                if device == \"cuda\":\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif device == \"mps\":\n",
    "                    torch.mps.empty_cache()\n",
    "        \n",
    "        # DataFrame ìƒì„± (decoding strategyë¥¼ rowë¡œ)\n",
    "        df = pd.DataFrame(results_data).T\n",
    "        \n",
    "        # ì—´ ì´ë¦„ì„ iteration ë²ˆí˜¸ë¡œ ì„¤ì •\n",
    "        df.columns = [f\"iteration_{i}\" for i in range(df.shape[1])]\n",
    "        \n",
    "        # CSV ì €ì¥\n",
    "        df.to_csv(output_csv)\n",
    "        \n",
    "        print(f\" âœ“ ({len(df)} strategies)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {RESULTS_DIR}\")\n",
    "\n",
    "# ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì •ë¦¬ (ìƒˆ ì‹œí€€ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ê³„ì‚° í•„ìš”)\n",
    "embeddings_dir = Path('results/embeddings')\n",
    "if embeddings_dir.exists():\n",
    "    removed = 0\n",
    "    for cache_file in embeddings_dir.glob('**/*.pkl'):\n",
    "        try:\n",
    "            cache_file.unlink()\n",
    "            removed += 1\n",
    "        except Exception as e:\n",
    "            print(f'  ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {cache_file} ({e})')\n",
    "    print(f'ğŸ§¹ ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì‚­ì œ ì™„ë£Œ: {removed} files')\n",
    "else:\n",
    "    print('ğŸ§¹ ê¸°ì¡´ ì„ë² ë”© ìºì‹œ ì—†ìŒ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a13f2",
   "metadata": {},
   "source": [
    "## ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff760ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ ê²°ê³¼ í™•ì¸:\n",
      "\n",
      "======================================================================\n",
      "\n",
      "DNABERT-2:\n",
      "  H4C1      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "NT-v2-500m:\n",
      "  H4C1      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 51 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"ìƒì„±ëœ ê²°ê³¼ í™•ì¸:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_key in models.keys():\n",
    "    model_name = model_key.replace(\"/\", \"-\")\n",
    "    model_dir = RESULTS_DIR / model_name\n",
    "    \n",
    "    print(f\"\\n{model_key}:\")\n",
    "    \n",
    "    for gene_id in gene_selection.keys():\n",
    "        csv_file = model_dir / f\"{gene_id}.csv\"\n",
    "        if csv_file.exists():\n",
    "            df = pd.read_csv(csv_file, index_col=0)\n",
    "            num_strategies = len(df)\n",
    "            num_iterations = len(df.columns)\n",
    "            print(f\"  {gene_id:10s}: {num_strategies:2d} strategies, {num_iterations:2d} iterations\")\n",
    "            if num_strategies > 0:\n",
    "                print(f\"            First strategy: {df.index[0]}\")\n",
    "        else:\n",
    "            print(f\"  {gene_id:10s}: âœ— FILE NOT FOUND\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
