{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28aeed5",
   "metadata": {},
   "source": [
    "## Step 1: ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e58eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïÑÏàò Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\n",
    "!pip install -q transformers einops huggingface_hub matplotlib scikit-learn biopython torch pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db422e70",
   "metadata": {},
   "source": [
    "## Step 2: Î™®Îìà ÏûÑÌè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55ee296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î™®Îì† Î™®Îìà ÏûÑÌè¨Ìä∏ ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "# ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨Î•º Í≤ΩÎ°úÏóê Ï∂îÍ∞Ä (Î™®Îìà Î°úÎìúÏö©)\n",
    "current_dir = Path('.').resolve()\n",
    "project_root = current_dir.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Î™®Îìà ÏûÑÌè¨Ìä∏\n",
    "from preparation import get_device, load_models\n",
    "from sequence_generation import (\n",
    "    fetch_gene_sequences, sort_genes_by_length, \n",
    "    DEFAULT_DECODING_STRATEGIES\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Î™®Îì† Î™®Îìà ÏûÑÌè¨Ìä∏ ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b9fca",
   "metadata": {},
   "source": [
    "## Step 3: ÎîîÎ∞îÏù¥Ïä§ Ï¥àÍ∏∞Ìôî Î∞è Î™®Îç∏ Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbe497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.9.1\n",
      "Using device: mps\n",
      "\n",
      "ÏÇ¨Ïö© Ï§ëÏù∏ ÎîîÎ∞îÏù¥Ïä§: mps\n"
     ]
    }
   ],
   "source": [
    "# ÎîîÎ∞îÏù¥Ïä§ Í∞êÏßÄ (CUDA / MPS / CPU)\n",
    "device = get_device()\n",
    "print(f\"\\nÏÇ¨Ïö© Ï§ëÏù∏ ÎîîÎ∞îÏù¥Ïä§: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c63ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading DNABERT-2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259b14373ab04ef58559e3ebfa32e09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DNABERT-2 Triton patch applied successfully.\n",
      "[DNABERT-2] Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DNABERT-2] Model loaded successfully.\n",
      "‚úÖ DNABERT-2 loaded successfully.\n",
      "[NT-v2-50m] Loading model...\n",
      "[NT-v2-50m] Model loaded successfully.\n",
      "‚úÖ NT-v2-50m loaded successfully.\n",
      "[NT-v2-500m] Loading model...\n",
      "[NT-v2-500m] Model loaded successfully.\n",
      "‚úÖ NT-v2-500m loaded successfully.\n",
      "\n",
      "üöÄ 3 model(s) ready!\n",
      "Î°úÎìúÎêú Î™®Îç∏: ['DNABERT-2', 'NT-v2-50m', 'NT-v2-500m']\n"
     ]
    }
   ],
   "source": [
    "# Î™®Îç∏ Î°úÎìú\n",
    "model_configs = {\n",
    "    \"DNABERT-2\": \"zhihan1996/DNABERT-2-117M\",\n",
    "    \"NT-v2-50m\": \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\",\n",
    "    \"NT-v2-500m\": \"InstaDeepAI/nucleotide-transformer-v2-500m-multi-species\",\n",
    "}\n",
    "\n",
    "models = load_models(device, model_configs=model_configs)\n",
    "print(f\"Î°úÎìúÎêú Î™®Îç∏: {list(models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f6df9",
   "metadata": {},
   "source": [
    "## Step 4: Ïú†Ï†ÑÏûê ÏãúÌÄÄÏä§ ÏàòÏßë Î∞è ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae20cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏÑ§Ï†ï:\n",
      "  - Î∞òÎ≥µ ÌöüÏàò: 30\n",
      "  - ÎßàÏä§ÌÇπ ÎπÑÏú®: 0.2\n",
      "  - Í≤∞Í≥º ÎîîÎ†âÌÜ†Î¶¨: results/sequences\n"
     ]
    }
   ],
   "source": [
    "# ÏÑ§Ï†ï\n",
    "NCBI_EMAIL = \"your_email@example.com\"\n",
    "ITERATIONS = 30  # ÏßÑÌôî Ïä§ÌÖù Ïàò\n",
    "MASK_RATIO = 0.2  # ÎßàÏä§ÌÇπ ÎπÑÏú®\n",
    "RESULTS_DIR = Path('results/sequences')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"ÏÑ§Ï†ï:\")\n",
    "print(f\"  - Î∞òÎ≥µ ÌöüÏàò: {ITERATIONS}\")\n",
    "print(f\"  - ÎßàÏä§ÌÇπ ÎπÑÏú®: {MASK_RATIO}\")\n",
    "print(f\"  - Í≤∞Í≥º ÎîîÎ†âÌÜ†Î¶¨: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d012fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching gene sequences from NCBI...\n",
      "Fetching H4C1 by UID NM_003538...\n",
      "  ‚úÖ Found and added sequence for H4C1 (Length: 402bp)\n",
      "Fetching TP53 by UID NM_000546...\n",
      "  ‚úÖ Found and added sequence for TP53 (Length: 2512bp)\n",
      "Fetching GAPDH by UID NM_002046...\n",
      "  ‚úÖ Found and added sequence for GAPDH (Length: 1285bp)\n",
      "Fetching GAPDHP1 by UID NG_001123...\n",
      "  ‚úÖ Found and added sequence for GAPDHP1 (Length: 1098bp)\n",
      "Fetching NORAD by UID NR_027451...\n",
      "  ‚úÖ Found and added sequence for NORAD (Length: 5378bp)\n",
      "Fetching STAT3 by UID NM_139276...\n",
      "  ‚úÖ Found and added sequence for STAT3 (Length: 4921bp)\n",
      "Fetching TTN by UID NM_001267550...\n",
      "  ‚úÖ Found and added sequence for TTN (Length: 109224bp)\n",
      "Fetching HBB by UID NM_000518...\n",
      "  ‚úÖ Found and added sequence for HBB (Length: 628bp)\n",
      "Fetching HOXC11 by UID NM_014212...\n",
      "  ‚úÖ Found and added sequence for HOXC11 (Length: 3261bp)\n",
      "Fetching HOTAIR by UID NR_003716...\n",
      "  ‚úÖ Found and added sequence for HOTAIR (Length: 2273bp)\n",
      "Fetching VEGFA by UID NM_003376...\n",
      "  ‚úÖ Found and added sequence for VEGFA (Length: 3609bp)\n",
      "Fetching NEAT1 by UID NR_003513...\n",
      "  ‚úÖ Found and added sequence for NEAT1 (Length: 3190bp)\n",
      "Fetching PTEN by UID NM_000314...\n",
      "  ‚úÖ Found and added sequence for PTEN (Length: 8515bp)\n",
      "Fetching PTENP1 by UID NR_023917...\n",
      "  ‚úÖ Found and added sequence for PTENP1 (Length: 3932bp)\n",
      "Fetching TPI1 by UID NM_000365...\n",
      "  ‚úÖ Found and added sequence for TPI1 (Length: 1351bp)\n",
      "Fetching TPI1P1 by UID NG_008262.2...\n",
      "  ‚úÖ Found and added sequence for TPI1P1 (Length: 1471bp)\n",
      "\n",
      "‚úÖ Gene fetching complete!\n",
      "Genes successfully loaded: ['H4C1', 'TP53', 'GAPDH', 'GAPDHP1', 'NORAD', 'STAT3', 'TTN', 'HBB', 'HOXC11', 'HOTAIR', 'VEGFA', 'NEAT1', 'PTEN', 'PTENP1', 'TPI1', 'TPI1P1']\n",
      "\n",
      "ÏàòÏßëÎêú Ïú†Ï†ÑÏûê:\n",
      "  - H4C1: 402 bp\n",
      "  - HBB: 628 bp\n",
      "  - GAPDHP1: 1098 bp\n",
      "  - GAPDH: 1285 bp\n",
      "  - TPI1: 1351 bp\n",
      "  - TPI1P1: 1471 bp\n",
      "  - HOTAIR: 2273 bp\n",
      "  - TP53: 2512 bp\n",
      "  - NEAT1: 3190 bp\n",
      "  - HOXC11: 3261 bp\n",
      "  - VEGFA: 3609 bp\n",
      "  - PTENP1: 3932 bp\n",
      "  - STAT3: 4921 bp\n",
      "  - NORAD: 5378 bp\n",
      "  - PTEN: 8515 bp\n",
      "  - TTN: 109224 bp\n"
     ]
    }
   ],
   "source": [
    "# Ïú†Ï†ÑÏûê ÏãúÌÄÄÏä§ ÏàòÏßë\n",
    "gene_selection = fetch_gene_sequences(NCBI_EMAIL)\n",
    "gene_selection = sort_genes_by_length(gene_selection)\n",
    "\n",
    "print(\"\\nÏàòÏßëÎêú Ïú†Ï†ÑÏûê:\")\n",
    "for gene, seq in gene_selection.items():\n",
    "    print(f\"  - {gene}: {len(seq)} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f3c739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (18205 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (18205 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌÜ†ÌÅ∞ Í∞úÏàò\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/m60tntks4_55jf79w27yb1t40000gn/T/ipykernel_54248/2178913799.py:40: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(token_length_df.style.applymap(highlight_over_limit))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4b9bb_row7_col0, #T_4b9bb_row8_col0, #T_4b9bb_row8_col1, #T_4b9bb_row8_col2, #T_4b9bb_row14_col0, #T_4b9bb_row14_col1, #T_4b9bb_row14_col2, #T_4b9bb_row16_col0, #T_4b9bb_row16_col1, #T_4b9bb_row16_col2 {\n",
       "  color: #b91c1c;\n",
       "  font-weight: 600;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4b9bb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_4b9bb_level0_col0\" class=\"col_heading level0 col0\" >DNABERT-2</th>\n",
       "      <th id=\"T_4b9bb_level0_col1\" class=\"col_heading level0 col1\" >NT-v2-500m</th>\n",
       "      <th id=\"T_4b9bb_level0_col2\" class=\"col_heading level0 col2\" >NT-v2-50m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >gene</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row0\" class=\"row_heading level0 row0\" >GAPDH</th>\n",
       "      <td id=\"T_4b9bb_row0_col0\" class=\"data row0 col0\" >265.000000</td>\n",
       "      <td id=\"T_4b9bb_row0_col1\" class=\"data row0 col1\" >216.000000</td>\n",
       "      <td id=\"T_4b9bb_row0_col2\" class=\"data row0 col2\" >216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row1\" class=\"row_heading level0 row1\" >GAPDHP1</th>\n",
       "      <td id=\"T_4b9bb_row1_col0\" class=\"data row1 col0\" >222.000000</td>\n",
       "      <td id=\"T_4b9bb_row1_col1\" class=\"data row1 col1\" >184.000000</td>\n",
       "      <td id=\"T_4b9bb_row1_col2\" class=\"data row1 col2\" >184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row2\" class=\"row_heading level0 row2\" >H4C1</th>\n",
       "      <td id=\"T_4b9bb_row2_col0\" class=\"data row2 col0\" >91.000000</td>\n",
       "      <td id=\"T_4b9bb_row2_col1\" class=\"data row2 col1\" >68.000000</td>\n",
       "      <td id=\"T_4b9bb_row2_col2\" class=\"data row2 col2\" >68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row3\" class=\"row_heading level0 row3\" >HBB</th>\n",
       "      <td id=\"T_4b9bb_row3_col0\" class=\"data row3 col0\" >127.000000</td>\n",
       "      <td id=\"T_4b9bb_row3_col1\" class=\"data row3 col1\" >109.000000</td>\n",
       "      <td id=\"T_4b9bb_row3_col2\" class=\"data row3 col2\" >109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row4\" class=\"row_heading level0 row4\" >HOTAIR</th>\n",
       "      <td id=\"T_4b9bb_row4_col0\" class=\"data row4 col0\" >464.000000</td>\n",
       "      <td id=\"T_4b9bb_row4_col1\" class=\"data row4 col1\" >384.000000</td>\n",
       "      <td id=\"T_4b9bb_row4_col2\" class=\"data row4 col2\" >384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row5\" class=\"row_heading level0 row5\" >HOXC11</th>\n",
       "      <td id=\"T_4b9bb_row5_col0\" class=\"data row5 col0\" >648.000000</td>\n",
       "      <td id=\"T_4b9bb_row5_col1\" class=\"data row5 col1\" >547.000000</td>\n",
       "      <td id=\"T_4b9bb_row5_col2\" class=\"data row5 col2\" >547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row6\" class=\"row_heading level0 row6\" >NEAT1</th>\n",
       "      <td id=\"T_4b9bb_row6_col0\" class=\"data row6 col0\" >641.000000</td>\n",
       "      <td id=\"T_4b9bb_row6_col1\" class=\"data row6 col1\" >536.000000</td>\n",
       "      <td id=\"T_4b9bb_row6_col2\" class=\"data row6 col2\" >536.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row7\" class=\"row_heading level0 row7\" >NORAD</th>\n",
       "      <td id=\"T_4b9bb_row7_col0\" class=\"data row7 col0\" >1069.000000</td>\n",
       "      <td id=\"T_4b9bb_row7_col1\" class=\"data row7 col1\" >899.000000</td>\n",
       "      <td id=\"T_4b9bb_row7_col2\" class=\"data row7 col2\" >899.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row8\" class=\"row_heading level0 row8\" >PTEN</th>\n",
       "      <td id=\"T_4b9bb_row8_col0\" class=\"data row8 col0\" >1663.000000</td>\n",
       "      <td id=\"T_4b9bb_row8_col1\" class=\"data row8 col1\" >1421.000000</td>\n",
       "      <td id=\"T_4b9bb_row8_col2\" class=\"data row8 col2\" >1421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row9\" class=\"row_heading level0 row9\" >PTENP1</th>\n",
       "      <td id=\"T_4b9bb_row9_col0\" class=\"data row9 col0\" >771.000000</td>\n",
       "      <td id=\"T_4b9bb_row9_col1\" class=\"data row9 col1\" >658.000000</td>\n",
       "      <td id=\"T_4b9bb_row9_col2\" class=\"data row9 col2\" >658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row10\" class=\"row_heading level0 row10\" >STAT3</th>\n",
       "      <td id=\"T_4b9bb_row10_col0\" class=\"data row10 col0\" >983.000000</td>\n",
       "      <td id=\"T_4b9bb_row10_col1\" class=\"data row10 col1\" >822.000000</td>\n",
       "      <td id=\"T_4b9bb_row10_col2\" class=\"data row10 col2\" >822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row11\" class=\"row_heading level0 row11\" >TP53</th>\n",
       "      <td id=\"T_4b9bb_row11_col0\" class=\"data row11 col0\" >498.000000</td>\n",
       "      <td id=\"T_4b9bb_row11_col1\" class=\"data row11 col1\" >423.000000</td>\n",
       "      <td id=\"T_4b9bb_row11_col2\" class=\"data row11 col2\" >423.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row12\" class=\"row_heading level0 row12\" >TPI1</th>\n",
       "      <td id=\"T_4b9bb_row12_col0\" class=\"data row12 col0\" >269.000000</td>\n",
       "      <td id=\"T_4b9bb_row12_col1\" class=\"data row12 col1\" >227.000000</td>\n",
       "      <td id=\"T_4b9bb_row12_col2\" class=\"data row12 col2\" >227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row13\" class=\"row_heading level0 row13\" >TPI1P1</th>\n",
       "      <td id=\"T_4b9bb_row13_col0\" class=\"data row13 col0\" >291.000000</td>\n",
       "      <td id=\"T_4b9bb_row13_col1\" class=\"data row13 col1\" >247.000000</td>\n",
       "      <td id=\"T_4b9bb_row13_col2\" class=\"data row13 col2\" >247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row14\" class=\"row_heading level0 row14\" >TTN</th>\n",
       "      <td id=\"T_4b9bb_row14_col0\" class=\"data row14 col0\" >21715.000000</td>\n",
       "      <td id=\"T_4b9bb_row14_col1\" class=\"data row14 col1\" >18205.000000</td>\n",
       "      <td id=\"T_4b9bb_row14_col2\" class=\"data row14 col2\" >18205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row15\" class=\"row_heading level0 row15\" >VEGFA</th>\n",
       "      <td id=\"T_4b9bb_row15_col0\" class=\"data row15 col0\" >729.000000</td>\n",
       "      <td id=\"T_4b9bb_row15_col1\" class=\"data row15 col1\" >605.000000</td>\n",
       "      <td id=\"T_4b9bb_row15_col2\" class=\"data row15 col2\" >605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b9bb_level0_row16\" class=\"row_heading level0 row16\" >MEAN</th>\n",
       "      <td id=\"T_4b9bb_row16_col0\" class=\"data row16 col0\" >1902.875000</td>\n",
       "      <td id=\"T_4b9bb_row16_col1\" class=\"data row16 col1\" >1596.937500</td>\n",
       "      <td id=\"T_4b9bb_row16_col2\" class=\"data row16 col2\" >1596.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x30b6df070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ìïú ÌÜ†ÌÅ∞ ÌèâÍ∑† Í∏∏Ïù¥(bp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>DNABERT-2</th>\n",
       "      <th>NT-v2-500m</th>\n",
       "      <th>NT-v2-50m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GAPDH</th>\n",
       "      <td>4.849057</td>\n",
       "      <td>5.949074</td>\n",
       "      <td>5.949074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAPDHP1</th>\n",
       "      <td>4.945946</td>\n",
       "      <td>5.967391</td>\n",
       "      <td>5.967391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H4C1</th>\n",
       "      <td>4.417582</td>\n",
       "      <td>5.911765</td>\n",
       "      <td>5.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HBB</th>\n",
       "      <td>4.944882</td>\n",
       "      <td>5.761468</td>\n",
       "      <td>5.761468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOTAIR</th>\n",
       "      <td>4.898707</td>\n",
       "      <td>5.919271</td>\n",
       "      <td>5.919271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOXC11</th>\n",
       "      <td>5.032407</td>\n",
       "      <td>5.961609</td>\n",
       "      <td>5.961609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEAT1</th>\n",
       "      <td>4.976599</td>\n",
       "      <td>5.951493</td>\n",
       "      <td>5.951493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORAD</th>\n",
       "      <td>5.030870</td>\n",
       "      <td>5.982202</td>\n",
       "      <td>5.982202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTEN</th>\n",
       "      <td>5.120265</td>\n",
       "      <td>5.992259</td>\n",
       "      <td>5.992259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTENP1</th>\n",
       "      <td>5.099870</td>\n",
       "      <td>5.975684</td>\n",
       "      <td>5.975684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAT3</th>\n",
       "      <td>5.006104</td>\n",
       "      <td>5.986618</td>\n",
       "      <td>5.986618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP53</th>\n",
       "      <td>5.044177</td>\n",
       "      <td>5.938534</td>\n",
       "      <td>5.938534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPI1</th>\n",
       "      <td>5.022305</td>\n",
       "      <td>5.951542</td>\n",
       "      <td>5.951542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPI1P1</th>\n",
       "      <td>5.054983</td>\n",
       "      <td>5.955466</td>\n",
       "      <td>5.955466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTN</th>\n",
       "      <td>5.029887</td>\n",
       "      <td>5.999670</td>\n",
       "      <td>5.999670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEGFA</th>\n",
       "      <td>4.950617</td>\n",
       "      <td>5.965289</td>\n",
       "      <td>5.965289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>4.964016</td>\n",
       "      <td>5.948083</td>\n",
       "      <td>5.948083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model    DNABERT-2  NT-v2-500m  NT-v2-50m\n",
       "gene                                     \n",
       "GAPDH     4.849057    5.949074   5.949074\n",
       "GAPDHP1   4.945946    5.967391   5.967391\n",
       "H4C1      4.417582    5.911765   5.911765\n",
       "HBB       4.944882    5.761468   5.761468\n",
       "HOTAIR    4.898707    5.919271   5.919271\n",
       "HOXC11    5.032407    5.961609   5.961609\n",
       "NEAT1     4.976599    5.951493   5.951493\n",
       "NORAD     5.030870    5.982202   5.982202\n",
       "PTEN      5.120265    5.992259   5.992259\n",
       "PTENP1    5.099870    5.975684   5.975684\n",
       "STAT3     5.006104    5.986618   5.986618\n",
       "TP53      5.044177    5.938534   5.938534\n",
       "TPI1      5.022305    5.951542   5.951542\n",
       "TPI1P1    5.054983    5.955466   5.955466\n",
       "TTN       5.029887    5.999670   5.999670\n",
       "VEGFA     4.950617    5.965289   5.965289\n",
       "MEAN      4.964016    5.948083   5.948083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÌÜ†ÌÅ∞ Í∏∏Ïù¥ ÌÖåÏù¥Î∏î (Î™®Îç∏Î≥Ñ / Ïú†Ï†ÑÏûêÎ≥Ñ)\n",
    "token_length_rows = []\n",
    "\n",
    "for model_label, model_instance in models.items():\n",
    "    tokenizer = model_instance.tokenizer\n",
    "    for gene_id, sequence in gene_selection.items():\n",
    "        enc = tokenizer(sequence, add_special_tokens=True, truncation=False)\n",
    "        token_len = len(enc[\"input_ids\"])\n",
    "        avg_token_bp = len(sequence) / token_len if token_len else float('nan')\n",
    "        token_length_rows.append({\n",
    "            \"gene\": gene_id,\n",
    "            \"model\": model_label,\n",
    "            \"token_len\": token_len,\n",
    "            \"avg_token_bp\": avg_token_bp,\n",
    "        })\n",
    "\n",
    "token_length_df = (\n",
    "    pd.DataFrame(token_length_rows)\n",
    "    .pivot(index=\"gene\", columns=\"model\", values=\"token_len\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "avg_token_bp_df = (\n",
    "    pd.DataFrame(token_length_rows)\n",
    "    .pivot(index=\"gene\", columns=\"model\", values=\"avg_token_bp\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Î™®Îç∏Î≥Ñ ÌèâÍ∑† (Ïú†Ï†ÑÏûê ÌèâÍ∑†)\n",
    "token_length_df.loc[\"MEAN\"] = token_length_df.mean(axis=0)\n",
    "avg_token_bp_df.loc[\"MEAN\"] = avg_token_bp_df.mean(axis=0)\n",
    "\n",
    "# 1024 Ï¥àÍ≥º Í∞ïÏ°∞ Ïä§ÌÉÄÏùº\n",
    "def highlight_over_limit(value, limit=1024):\n",
    "    if pd.isna(value):\n",
    "        return ''\n",
    "    return 'color: #b91c1c; font-weight: 600;' if value > limit else ''\n",
    "\n",
    "print(\"ÌÜ†ÌÅ∞ Í∞úÏàò\")\n",
    "display(token_length_df.style.applymap(highlight_over_limit))\n",
    "\n",
    "print(\"Ìïú ÌÜ†ÌÅ∞ ÌèâÍ∑† Í∏∏Ïù¥(bp)\")\n",
    "display(avg_token_bp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3992a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÏãúÌÄÄÏä§ ÏÉùÏÑ± Ï§ë...\n",
      "======================================================================\n",
      "\n",
      "Î™®Îç∏: DNABERT-2\n",
      "  H4C1... ‚úì (4 strategies)\n",
      "  HBB... ‚úì (4 strategies)\n",
      "  GAPDHP1... ‚úì (4 strategies)\n",
      "  GAPDH... ‚úì (4 strategies)\n",
      "  TPI1... ‚úì (4 strategies)\n",
      "  TPI1P1... ‚úì (4 strategies)\n",
      "  HOTAIR..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 512 to 516\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 516 to 519\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 519 to 520\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 520 to 521\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 521 to 525\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 525 to 528\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 528 to 532\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 532 to 534\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 534 to 538\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 538 to 544\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úì (4 strategies)\n",
      "  TP53..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 544 to 546\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 546 to 553\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 553 to 557\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 557 to 558\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 558 to 566\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 566 to 570\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 570 to 576\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 576 to 578\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 578 to 582\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 582 to 591\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 591 to 592\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úì (4 strategies)\n",
      "  NEAT1..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 592 to 641\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 641 to 645\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 645 to 651\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 651 to 654\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 654 to 660\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 660 to 666\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 666 to 674\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 674 to 676\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 676 to 680\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 680 to 683\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 683 to 684\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 684 to 691\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 691 to 695\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 695 to 699\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 699 to 700\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 700 to 702\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 702 to 704\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 704 to 705\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 705 to 706\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 706 to 711\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 711 to 713\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 713 to 719\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 719 to 724\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 724 to 729\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 729 to 736\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 736 to 738\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 738 to 744\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úì (4 strategies)\n",
      "  HOXC11... ‚úì (4 strategies)\n",
      "  VEGFA..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 744 to 748\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 748 to 751\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 751 to 758\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 758 to 766\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 766 to 772\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 772 to 776\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 776 to 782\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 782 to 788\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 788 to 792\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 792 to 798\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 798 to 799\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 799 to 806\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 806 to 814\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 814 to 819\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 819 to 827\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 827 to 828\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 828 to 830\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 830 to 835\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úì (4 strategies)\n",
      "  PTENP1..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 835 to 839\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 839 to 845\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 845 to 848\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 848 to 852\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 852 to 861\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 861 to 862\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 862 to 866\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úì (4 strategies)\n",
      "  STAT3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 866 to 983\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 983 to 988\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 988 to 989\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 989 to 1000\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1000 to 1008\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1008 to 1014\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1014 to 1018\n",
      "  warnings.warn(\n",
      "/Users/leeminjae/.cache/huggingface/modules/transformers_modules/_7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 1018 to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úì (4 strategies)\n",
      "  NORAD... ‚úì (4 strategies)\n",
      "  PTEN... ‚úì (4 strategies)\n",
      "  TTN... ‚úì (4 strategies)\n",
      "\n",
      "Î™®Îç∏: NT-v2-50m\n",
      "  H4C1... ‚úì (4 strategies)\n",
      "  HBB... ‚úì (4 strategies)\n",
      "  GAPDHP1... ‚úì (4 strategies)\n",
      "  GAPDH... ‚úì (4 strategies)\n",
      "  TPI1... ‚úì (4 strategies)\n",
      "  TPI1P1... ‚úì (4 strategies)\n",
      "  HOTAIR... ‚úì (4 strategies)\n",
      "  TP53... ‚úì (4 strategies)\n",
      "  NEAT1... ‚úì (4 strategies)\n",
      "  HOXC11... ‚úì (4 strategies)\n",
      "  VEGFA... ‚úì (4 strategies)\n",
      "  PTENP1... ‚úì (4 strategies)\n",
      "  STAT3... ‚úì (4 strategies)\n",
      "  NORAD... ‚úì (4 strategies)\n",
      "  PTEN... ‚úì (4 strategies)\n",
      "  TTN... ‚úì (4 strategies)\n",
      "\n",
      "Î™®Îç∏: NT-v2-500m\n",
      "  H4C1... ‚úì (4 strategies)\n",
      "  HBB... ‚úì (4 strategies)\n",
      "  GAPDHP1... ‚úì (4 strategies)\n",
      "  GAPDH... ‚úì (4 strategies)\n",
      "  TPI1... ‚úì (4 strategies)\n",
      "  TPI1P1... ‚úì (4 strategies)\n",
      "  HOTAIR... ‚úì (4 strategies)\n",
      "  TP53... ‚úì (4 strategies)\n",
      "  NEAT1... ‚úì (4 strategies)\n",
      "  HOXC11... ‚úì (4 strategies)\n",
      "  VEGFA... ‚úì (4 strategies)\n",
      "  PTENP1... ‚úì (4 strategies)\n",
      "  STAT3... ‚úì (4 strategies)\n",
      "  NORAD... ‚úì (4 strategies)\n",
      "  PTEN... ‚úì (4 strategies)\n",
      "  TTN... ‚úì (4 strategies)\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ÏãúÌÄÄÏä§ ÏÉùÏÑ± ÏôÑÎ£å!\n",
      "Í≤∞Í≥º Ï†ÄÏû• ÏúÑÏπò: results/sequences\n",
      "üßπ Í∏∞Ï°¥ ÏûÑÎ≤†Îî© Ï∫êÏãú ÏÇ≠Ï†ú ÏôÑÎ£å: 4 files\n"
     ]
    }
   ],
   "source": [
    "# ÏãúÌÄÄÏä§ ÏÉùÏÑ± Î∞è CSV Ï†ÄÏû•\n",
    "print(\"\\nÏãúÌÄÄÏä§ ÏÉùÏÑ± Ï§ë...\\n\" + \"=\"*70)\n",
    "\n",
    "for model_label, model_instance in models.items():\n",
    "    print(f\"\\nÎ™®Îç∏: {model_label}\")\n",
    "    \n",
    "    for gene_id, original_sequence in gene_selection.items():\n",
    "        print(f\"  {gene_id}...\", end=\"\", flush=True)\n",
    "        \n",
    "        # Ï∂úÎ†• Í≤ΩÎ°ú\n",
    "        model_name = model_label.replace(\"/\", \"-\")\n",
    "        model_dir = RESULTS_DIR / model_name\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_csv = model_dir / f\"{gene_id}.csv\"\n",
    "        \n",
    "        # Í≤∞Í≥º Ï†ÄÏû•Ïö© Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "        results_data = {}\n",
    "        \n",
    "        for strategy_base_key, strategy_cfg in DEFAULT_DECODING_STRATEGIES.items():\n",
    "            strategy_type = strategy_cfg[\"type\"]\n",
    "            temperatures = strategy_cfg.get(\"temperatures\", [1.0])\n",
    "            top_k = strategy_cfg.get(\"top_k\", 50)\n",
    "            \n",
    "            for temp in temperatures:\n",
    "                # Ï†ÑÎûµ Ïù¥Î¶Ñ\n",
    "                if strategy_type == \"greedy\":\n",
    "                    strategy_key = strategy_base_key\n",
    "                else:\n",
    "                    strategy_key = f\"{strategy_base_key}_t{temp}\"\n",
    "                \n",
    "                # ÏãúÌÄÄÏä§ ÏÉùÏÑ±\n",
    "                generated_sequences = model_instance.run(\n",
    "                    sequence=original_sequence,\n",
    "                    steps=ITERATIONS,\n",
    "                    mask_ratio=MASK_RATIO,\n",
    "                    strategy=strategy_type,\n",
    "                    temperature=temp,\n",
    "                    top_k=top_k,\n",
    "                    save_all=True,\n",
    "                    save_interval=1\n",
    "                )\n",
    "                \n",
    "                # Í≤∞Í≥º Ï†ÄÏû• (Í∞Å iterationÏùÑ columnÏúºÎ°ú)\n",
    "                results_data[strategy_key] = generated_sequences\n",
    "                \n",
    "                # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "                del generated_sequences\n",
    "                gc.collect()\n",
    "                if device == \"cuda\":\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif device == \"mps\":\n",
    "                    torch.mps.empty_cache()\n",
    "        \n",
    "        # DataFrame ÏÉùÏÑ± (decoding strategyÎ•º rowÎ°ú)\n",
    "        df = pd.DataFrame(results_data).T\n",
    "        \n",
    "        # Ïó¥ Ïù¥Î¶ÑÏùÑ iteration Î≤àÌò∏Î°ú ÏÑ§Ï†ï\n",
    "        df.columns = [f\"iteration_{i}\" for i in range(df.shape[1])]\n",
    "        \n",
    "        # CSV Ï†ÄÏû•\n",
    "        df.to_csv(output_csv)\n",
    "        \n",
    "        print(f\" ‚úì ({len(df)} strategies)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ÏãúÌÄÄÏä§ ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "print(f\"Í≤∞Í≥º Ï†ÄÏû• ÏúÑÏπò: {RESULTS_DIR}\")\n",
    "\n",
    "# Í∏∞Ï°¥ ÏûÑÎ≤†Îî© Ï∫êÏãú Ï†ïÎ¶¨ (ÏÉà ÏãúÌÄÄÏä§ Í∏∞Ï§ÄÏúºÎ°ú Îã§Ïãú Í≥ÑÏÇ∞ ÌïÑÏöî)\n",
    "embeddings_dir = Path('results/embeddings')\n",
    "if embeddings_dir.exists():\n",
    "    removed = 0\n",
    "    for cache_file in embeddings_dir.glob('**/*.pkl'):\n",
    "        try:\n",
    "            cache_file.unlink()\n",
    "            removed += 1\n",
    "        except Exception as e:\n",
    "            print(f'  Ï∫êÏãú ÏÇ≠Ï†ú Ïã§Ìå®: {cache_file} ({e})')\n",
    "    print(f'üßπ Í∏∞Ï°¥ ÏûÑÎ≤†Îî© Ï∫êÏãú ÏÇ≠Ï†ú ÏôÑÎ£å: {removed} files')\n",
    "else:\n",
    "    print('üßπ Í∏∞Ï°¥ ÏûÑÎ≤†Îî© Ï∫êÏãú ÏóÜÏùå')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a13f2",
   "metadata": {},
   "source": [
    "## Í≤∞Í≥º ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff760ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏÉùÏÑ±Îêú Í≤∞Í≥º ÌôïÏù∏:\n",
      "\n",
      "======================================================================\n",
      "\n",
      "DNABERT-2:\n",
      "  H4C1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "NT-v2-50m:\n",
      "  H4C1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "NT-v2-500m:\n",
      "  H4C1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HBB       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDHP1   :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  GAPDH     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TPI1P1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOTAIR    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TP53      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NEAT1     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  HOXC11    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  VEGFA     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTENP1    :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  STAT3     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  NORAD     :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  PTEN      :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "  TTN       :  4 strategies, 31 iterations\n",
      "            First strategy: greedy\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"ÏÉùÏÑ±Îêú Í≤∞Í≥º ÌôïÏù∏:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_key in models.keys():\n",
    "    model_name = model_key.replace(\"/\", \"-\")\n",
    "    model_dir = RESULTS_DIR / model_name\n",
    "    \n",
    "    print(f\"\\n{model_key}:\")\n",
    "    \n",
    "    for gene_id in gene_selection.keys():\n",
    "        csv_file = model_dir / f\"{gene_id}.csv\"\n",
    "        if csv_file.exists():\n",
    "            df = pd.read_csv(csv_file, index_col=0)\n",
    "            num_strategies = len(df)\n",
    "            num_iterations = len(df.columns)\n",
    "            print(f\"  {gene_id:10s}: {num_strategies:2d} strategies, {num_iterations:2d} iterations\")\n",
    "            if num_strategies > 0:\n",
    "                print(f\"            First strategy: {df.index[0]}\")\n",
    "        else:\n",
    "            print(f\"  {gene_id:10s}: ‚úó FILE NOT FOUND\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
